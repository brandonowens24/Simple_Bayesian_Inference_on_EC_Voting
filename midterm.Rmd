---
title: "Presidential Election: Bayesian Inference"
author: "Brandon Owens"
date: "2024-03-01"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Import Necessary Libraries
```{r import_libraries}
library(dplyr)
library(nflfastR)
library(ggplot2)
```

## Import Polling Data and Cleaning
```{r ignore_outside_parties}
polls <- read.csv("csvs/presidential_polls.csv")
 
total_sum = sum(polls$rawpoll_trump) + sum(polls$rawpoll_clinton)


polls$norm_trump <- (polls$rawpoll_trump / total_sum) * 10000
polls$norm_clinton <- (polls$rawpoll_clinton / total_sum) * 10000

polls$state <-as.factor(polls$state)

```
Imported polling data. Normalized all raw scores for only Trump and Clinton. This analysis will ignore the other candidates!
Also changed the states to factors so that I can group them later. 


```{r see_poll_locations}
levels(polls$state)
```
Some states have multiple sub polls as seen by the levels of the factor. I just want all of the subpolls to be identified as belonging to that state. 


```{r group_state}
polls$state <- gsub("Nebraska CD-1|Nebraska CD-2|Nebraska CD-3", "Nebraska", polls$state)
polls$state <- gsub("Maine CD-1|Maine CD-2", "Maine", polls$state)
polls$state <-as.factor(polls$state)
levels(polls$state)

polls <- polls[polls$grade == c("A", "A-", "A+", "B", "B+", "B-"), ]
```
Here, I made the sub polls in Nebraska and Maine associated with the state and removed all polling that didn't at least have a "B-" grade.

## Grabbing Sample Means and Variances for Both Candidates
```{r determine_sample_values, message=FALSE, warning=FALSE}
state_grouping <- polls  %>%
  group_by(state) %>%
  summarize(state = state, 
            trump_mean = mean(norm_trump, na.rm = TRUE),
            clinton_mean = mean(norm_clinton, na.rm = TRUE),
            trump_var = var(norm_trump, na.rm = TRUE), 
            clinton_var = var(norm_clinton, na.rm = TRUE)) %>%
  distinct(state, .keep_all = TRUE)

state_grouping

```
Utilizing the state grouping, I grab each candidates sample mean and sample variance that will be later used in the posteriors for each individual state.

## Setting Up Priors
```{r determine_regions}
states <- c(levels(state_grouping$state))
regions <- c("farwest", "rockies", "southwest", "southeast", "plains", "gl", "mideast", "ne")

farwest <- c("Washington", "Oregon", "Nevada", "California", "Alaska", "Hawaii")
rockies <- c("Montana", "Idaho", "Wyoming", "Utah", "Colorado")
southwest <- c("Arizona", "New Mexico", "Texas", "Oklahoma")
southeast <- c("Arkansas", "Louisiana", "Mississippi", "Alabama", "Georgia", "South Carolina", "North Carolina", "Florida", "Tennessee", "Kentucky", "West Virginia", "Virginia")
plains <- c("North Dakota", "South Dakota", "Nebraska", "Kansas", "Missouri", "Iowa", "Minnesota")
gl <- c("Wisconsin", "Michigan", "Illinois", "Indiana", "Ohio")
mideast <- c("District of Columbia", "Pennsylvania", "New York", "New Jersey", "Delaware", "Maryland")
ne <- c("Vermont", "New Hampshire", "Connecticut", "Rhode Island", "Massachusetts", "Maine")
```
I would like the prior distributions to be based off of surrounding geography for each state. Here we break up the U.S. into respective regions based on geographical areas.

```{r find_prior_params}
priors <- data.frame(column1=character(),
                            column2=character(),
                            column3=numeric(),
                            column4=numeric(),
                            column5=numeric(),
                            column6=numeric())

for (region in regions){
  region_states <- get(region)
  
  for (sel_state in region_states){
    polls_region = polls[polls$state %in% region_states, ]
    
    regional_states_polls = polls_region[polls_region$state != sel_state, ]
    trump_prior_var = var(regional_states_polls$norm_trump)
    clinton_prior_var = var(regional_states_polls$norm_trump)
    
    regional_states_df = state_grouping[state_grouping$state %in% region_states, ]
    regional_states_df$region <- region
   

    tmp_state_df <- regional_states_df[regional_states_df$state != sel_state, ] %>%
      group_by(region) %>%
      summarise(state = sel_state,
        trump_prior_mean = mean(trump_mean), 
        clinton_prior_mean = mean(clinton_mean),
        trump_prior_var = trump_prior_var,
        clinton_prior_var = clinton_prior_var)
    
    priors <- rbind(priors, tmp_state_df)
  }
}
```
Creating a data frame that includes the prior means and variances for each candidate for each state. The priors are based on the means and variances for all surrounding states in the region excluding the state we are obtaining the parameters for.


```{r ignore_US_poll}
prior = priors[priors$state != "U.S.",]
state_grouping = state_grouping[state_grouping$state != "U.S.",]
```
We are going to ignore the national polls


```{r view_dfs}
prior
state_grouping
```
Obtain a quick view of the data frames


# Bayesian Data Analysis
## Calculate Posterior mean and variance
```{r posteriors}
states <- states[states != "U.S."]
state_counts<- table(polls$state)
result_df <- data.frame(state = character(),
                        post_mean_trump = numeric(),
                        post_var_trump = numeric(),
                        post_mean_clinton = numeric(),
                        post_var_clinton = numeric())

for (state in states){
  n_count <- as.numeric(state_counts[state])

  trump_sample_mean <- state_grouping[state_grouping$state == state, ]$trump_mean
  trump_sample_var <- state_grouping[state_grouping$state == state, ]$trump_var
  clinton_sample_mean <- state_grouping[state_grouping$state == state, ]$clinton_mean
  clinton_sample_var <- state_grouping[state_grouping$state == state, ]$clinton_var
  trump_prior_mean <- prior[prior$state == state, ]$trump_prior_mean
  trump_prior_var <- prior[prior$state == state, ]$trump_prior_var
  clinton_prior_mean <- prior[prior$state == state, ]$clinton_prior_mean
  clinton_prior_mean <- prior[prior$state == state, ]$clinton_prior_var
  
  
  
  post_mean_trump <- ((((1/trump_prior_var)*trump_prior_mean) + ((n_count/trump_sample_var)*trump_sample_mean))) / (((1/trump_prior_var) + (n_count/trump_sample_var)))
  
  post_var_trump <- 1/((1/trump_prior_var) + (n_count/trump_sample_var))

  post_mean_clinton <- ((((1/clinton_prior_var)*clinton_prior_mean) + ((n_count/clinton_sample_var)*clinton_sample_mean))) / (((1/clinton_prior_var) + (n_count/clinton_sample_var)))
  
  post_var_clinton <- 1/((1/clinton_prior_var) + (n_count/clinton_sample_var))

  temp_df <- data.frame(state = state, 
                        post_mean_trump = post_mean_trump, 
                        post_var_trump = post_var_trump,
                        post_mean_clinton = post_mean_clinton,
                        post_var_clinton = post_var_clinton)
  result_df <- rbind(result_df, temp_df)
}
```
Determine posterior means and variances for each candidate for each state using conjugate normal poseterior.


```{r posterior_df_view}
result_df
```

## Simulate 10,000 Values for Posterior Distribution
```{r plot_posteriors_and_sample}
predict_ec <- data.frame(State = character(),
                         tp = numeric(),
                         cp = numeric())

for (state in states) {
  state_dist <- result_df[result_df$state == state, ]
  trump <- rnorm(10000, state_dist$post_mean_trump, sqrt(result_df$post_var_trump))
  clinton <- rnorm(10000, state_dist$post_mean_clinton, sqrt(result_df$post_var_clinton))

  dist_df <- data.frame(trump, clinton)
  
  p <- ggplot(dist_df) + 
    geom_density(aes(x=trump), color = "red", adjust = 2) + 
    geom_density(aes(x = clinton), color = "blue", adjust = 2) +
    labs(title = paste(state), x = "Theta")
  
  print(p)
  
  

  x_trump <- sample(trump, 1000, replace = TRUE)
  x_clinton <- sample(clinton, 1000, replace = TRUE)
  
  predict_ec <- rbind(predict_ec, data.frame(State = state, tp = x_trump, cp = x_clinton))
  
  ggsave(paste("density_plot_", state, ".png", sep = ""), plot = p, width = 10, height = 6)
}

```
1,000 samples taken with resampling from the 10,000 generated values. These will be used to see which candidate will win the election from sampled 1,000 elections. 
Simulate 10,000 values for each candidate for each state and plot their posteriors. With resampling, sample 1,000 of these voter percentages for each candidate and put them in a dataframe for each state for future usage.

## Load In Electoral College Dataset 
```{r determine_state_electoral_college_votes}
ec <- read.csv("csvs/Electoral_College.csv")
ec <- filter(ec, Year == 2016)
ec <- ec %>% mutate(State = ifelse(State == "D.C.", "District of Columbia", State))
ec
```
## Predict Electoral College Voting
```{r predict_winner}
predict_ec$State <- as.factor(predict_ec$State)

ec_results <- predict_ec %>%
  mutate(outcome = ifelse(tp>cp, 1, 0)) %>%
  group_by(State) %>%
  summarize(Winner = ifelse((sum(outcome) > 500), "Trump", "Clinton"))

simulated_election_results <- merge(ec_results, ec, by="State") %>%
  group_by(Winner) %>%
  summarize(Electoral_College_Votes = sum(Votes))

ec_results
simulated_election_results
```
If Trump had a higher percentage for a state than Clinton, he will win that state and Vice Versa. Calculate who has more wins for each state and that candidate will win the state. This will simulate who would win the election. Here, Clinton wins with 312 votes.


```{r}
acc <- predict_ec %>%
  mutate(outcome = ifelse(tp>cp, 1, 0)) %>%
  group_by(State) %>%
  summarize(Trump_Win = sum(outcome),
            Clinton_Win = 1000 - Trump_Win)

acc$Winner <- c("T", "T", "T", "T", "C", "C", "C", "C", "C", "T", "T", "C", "T", "C",
                "T", "T", "T", "T", "T", "C", "C", "C", "T", "C", "T", "T", "T",
                "T", "C", "C", "C", "C", "C", "T", "T", "T", "T", "C", "T", "C", "T", "T", 
                "T", "T", "T", "C", "C", "C", "T", "T", "T")

accuracy <- acc %>%
  mutate(TCorrect = ifelse(Winner == "T", Trump_Win, 0), 
         CCorrect = ifelse(Winner == "C", Clinton_Win, 0)) %>%
  summarize(Total_Acc = sum(TCorrect + CCorrect) / (51000))

accuracy
```
 Calculating model accuracy by seeing for each state out of our 1000 simulates how many times the candidate that actually won that state won in our simulations. The model was ~86.5% accurate!



